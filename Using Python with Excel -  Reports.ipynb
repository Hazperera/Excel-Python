{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Managing multiple sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Shift Region Sales Rep  Product  Cost per  Units Sold\n",
      "0       1  South    Meggan    Paper        15         163\n",
      "1       1  South    Charis  Stapler        25         108\n",
      "2       1  South    Shayne   Pencil         5         118\n",
      "3       1  North   Krystin      Pen        10          37\n",
      "4       1  South       Leo    Paper        15         131\n",
      "..    ...    ...       ...      ...       ...         ...\n",
      "94      3  South     Willa      Pen        10          42\n",
      "95      3   West    Shayne    Paper        15         168\n",
      "96      3   East    Adrian   Binder        30         132\n",
      "97      3   East     Willa    Paper        15         111\n",
      "98      3   East     Diann   Folder        17         151\n",
      "\n",
      "[298 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_excel('shifts.xlsx', sheet_name='Sheet')\n",
    "df_2 = pd.read_excel('shifts.xlsx', sheet_name='Sheet1')\n",
    "df_3 = pd.read_excel('shift_3.xlsx')\n",
    "\n",
    "#concatenation function - combine all of the data frames as long as they have the same header columns \n",
    "# sort equal to false -columns stay in the same order\n",
    "\n",
    "df_all = pd.concat([df_1, df_2, df_3], sort=False)\n",
    "print(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Shift Region Sales Rep Product  Cost per  Units Sold\n",
      "50      1  South  Shirlene  Binder        30         176\n",
      "50      2  North   Jenifer  Pencil         5          62\n",
      "50      3   West    Conrad  Folder        17          51\n"
     ]
    }
   ],
   "source": [
    "# printing row 50\n",
    "#analyzing similarly formatted reports over time\n",
    "\n",
    "print(df_all.loc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shift\n",
      "1    114.767677\n",
      "2    112.460000\n",
      "3    109.343434\n",
      "Name: Units Sold, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_all.groupby(['Shift']).mean()['Units Sold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = None - remove indices\n",
    "to_excel = df_all.to_excel('all_shifts.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('all_shifts.xlsx')\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add new column (bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_col = ws['G1']\n",
    "total_col.font = Font(bold=True)\n",
    "total_col.value = 'Total'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill the new column\n",
    "- cost per unit is in row E \n",
    "- number of units sold is in row F\n",
    "- new column is in row G\n",
    "- create two variables to store the strings for the columns\n",
    "- create a for loop to iterate through all the rows in these columns\n",
    "- final row in our data is 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_col, f_col = ['E', 'F']\n",
    "for row in range(2,300): # first row excluded - header values\n",
    "    result_cell = 'G{}'.format(row)\n",
    "    e_value = ws[e_col + str(row)].value\n",
    "    f_vaue =  ws[f_col +str(row)].value\n",
    "    ws[result_cell] = e_value + f_vaue\n",
    "wb.save('totaled.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"screenshots/totaled.PNG\\\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Converting data\n",
    "\n",
    "### openpyxl module:     dataframe_to_rows\n",
    " - convert data frame into a format that's usable by openpyxl\n",
    " - no overwriting any saves or cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.utils.dataframe import dataframe_to_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook('regions.xlsx')\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Sales Rep  Cost per  Units Sold  Total\n",
      "0      Meggan        15         163   2445\n",
      "1      Charis        25         108   2700\n",
      "2      Shayne         5         118    590\n",
      "3     Krystin        10          37    370\n",
      "4         Leo        15         131   1965\n",
      "..        ...       ...         ...    ...\n",
      "293     Willa        10          42    420\n",
      "294    Shayne        15         168   2520\n",
      "295    Adrian        30         132   3960\n",
      "296     Willa        15         111   1665\n",
      "297     Diann        17         151   2567\n",
      "\n",
      "[298 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('all_shifts.xlsx')\n",
    "df1 = df[['Sales Rep', 'Cost per', 'Units Sold']]\n",
    "df1['Total'] = df1['Cost per']* df1['Units Sold']\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = dataframe_to_rows(df1, index=False)\n",
    "# for row in rows:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = dataframe_to_rows(df1, index=False)\n",
    "# for row in rows:\n",
    "#     for col in row:\n",
    "#         print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nested for loop - terate like a regular for loop while also keeping record of these row index and column index variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = dataframe_to_rows(df1, index=False)\n",
    "for r_idx, row in enumerate(rows,1):\n",
    "    for c_idx, col in enumerate(row,6):  #not to overwrite data instead 1 used 6\n",
    "        ws.cell(row=r_idx, column = c_idx, value=col)\n",
    "\n",
    "wb.save('combined.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'screenshots\\combined.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Parsing large spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = load_workbook ('template.xlsx')\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encode() method\n",
    "- Since Python 3.0, strings are stored as Unicode \n",
    "- convert unicoded strings into any encodings supported by Python\n",
    "- By default, Python uses utf-8 encoding\n",
    "\n",
    "### datatype casting\n",
    "- to conserve memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('crime.csv', encoding='utf=8', dtype={\"INCIDENT_NUMBER\": str, \n",
    "\"OFFENSE_CODE\": str, \"OFFENSE_CODE_GROUP\": str, \"OFFENSE_DESCRIPTION\": str, \n",
    "\"DISTRICT\": str, \"REPORTING_AREA\": str, \"SHOOTING\": str, \"YEAR\": str, \"MONTH\": str, \n",
    "\"DAY_OF_WEEK\": str, \"HOUR\": str })\n",
    "\n",
    "# search for an offense code-  counterfeiting\n",
    "\n",
    "df1 = df[df['OFFENSE_CODE_GROUP'] == 'Counterfeiting']\n",
    "\n",
    "# data trimming -  NumPy to replace nan values\n",
    "\n",
    "df1 = df1.replace(np.nan, 'N/A', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### round() function\n",
    " - rounds off to the given number of digits and returns the floating point number, if no number of digits is provided for round off , it rounds off the number to the nearest integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create percentage of crimes\n",
    "\n",
    "total_crimes = len(df.index)\n",
    "counterfeit = len(df1.index)\n",
    "perc_crimes = (counterfeit/total_crimes)*100\n",
    "\n",
    "perc_crimes = round(perc_crimes, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report about the number of counterfeiting crimes occurring each year by district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRICT  YEAR\n",
      "A1        2015    25\n",
      "          2016    57\n",
      "          2017    37\n",
      "          2018    27\n",
      "A15       2015     5\n",
      "          2016     2\n",
      "          2017     8\n",
      "          2018     3\n",
      "A7        2015     6\n",
      "          2016    16\n",
      "          2017    14\n",
      "          2018     8\n",
      "B2        2015    32\n",
      "          2016    68\n",
      "          2017    64\n",
      "          2018    28\n",
      "B3        2015    26\n",
      "          2016    44\n",
      "          2017    34\n",
      "          2018    23\n",
      "C11       2015    73\n",
      "          2016    98\n",
      "          2017    62\n",
      "          2018    41\n",
      "C6        2015    16\n",
      "          2016    28\n",
      "          2017    27\n",
      "          2018    21\n",
      "D14       2015     6\n",
      "          2016    32\n",
      "          2017    69\n",
      "          2018    15\n",
      "D4        2015    35\n",
      "          2016    64\n",
      "          2017    66\n",
      "          2018    49\n",
      "E13       2015    17\n",
      "          2016    42\n",
      "          2017    37\n",
      "          2018    18\n",
      "E18       2015    20\n",
      "          2016    26\n",
      "          2017    23\n",
      "          2018    17\n",
      "E5        2015    15\n",
      "          2016    17\n",
      "          2017    15\n",
      "          2018    11\n",
      "N/A       2017     1\n",
      "          2018     1\n",
      "Name: Count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ws['O8'].value = total_crimes\n",
    "ws['P8'].value = counterfeit\n",
    "ws['q8'].value = perc_crimes\n",
    "\n",
    "df1['Count'] = 1\n",
    "df2 = df1.groupby (['DISTRICT' , 'YEAR']).count()['Count']\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- counts are grouped by district and year and year values just repeat over and over for each district (unclear)\n",
    "\n",
    "### unstack() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRICT    A1  A15    A7    B2    B3   C11    C6   D14    D4   E13   E18  \\\n",
      "YEAR                                                                        \n",
      "2015      25.0  5.0   6.0  32.0  26.0  73.0  16.0   6.0  35.0  17.0  20.0   \n",
      "2016      57.0  2.0  16.0  68.0  44.0  98.0  28.0  32.0  64.0  42.0  26.0   \n",
      "2017      37.0  8.0  14.0  64.0  34.0  62.0  27.0  69.0  66.0  37.0  23.0   \n",
      "2018      27.0  3.0   8.0  28.0  23.0  41.0  21.0  15.0  49.0  18.0  17.0   \n",
      "\n",
      "DISTRICT    E5  N/A  \n",
      "YEAR                 \n",
      "2015      15.0  NaN  \n",
      "2016      17.0  NaN  \n",
      "2017      15.0  1.0  \n",
      "2018      11.0  1.0  \n"
     ]
    }
   ],
   "source": [
    "df1['Count'] = 1\n",
    "df2 = df1.groupby (['DISTRICT' , 'YEAR']).count()['Count'].unstack(level=0)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop() function\n",
    "\n",
    " - to remove Nan columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRICT    A1  A15    A7    B2    B3   C11    C6   D14    D4   E13   E18  \\\n",
      "YEAR                                                                        \n",
      "2015      25.0  5.0   6.0  32.0  26.0  73.0  16.0   6.0  35.0  17.0  20.0   \n",
      "2016      57.0  2.0  16.0  68.0  44.0  98.0  28.0  32.0  64.0  42.0  26.0   \n",
      "2017      37.0  8.0  14.0  64.0  34.0  62.0  27.0  69.0  66.0  37.0  23.0   \n",
      "2018      27.0  3.0   8.0  28.0  23.0  41.0  21.0  15.0  49.0  18.0  17.0   \n",
      "\n",
      "DISTRICT    E5  \n",
      "YEAR            \n",
      "2015      15.0  \n",
      "2016      17.0  \n",
      "2017      15.0  \n",
      "2018      11.0  \n"
     ]
    }
   ],
   "source": [
    "df1['Count'] = 1\n",
    "df2 = df1.groupby (['DISTRICT' , 'YEAR']).count()['Count'].unstack(level=0)\n",
    "df2.drop(columns='N/A', inplace=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert report to openpyxl format\n",
    "\n",
    "rows = dataframe_to_rows(df2)\n",
    "for r_idx, row in enumerate (rows,8):\n",
    "    for c_idx, value in enumerate(row,1):\n",
    "        ws.cell(row=r_idx, column=c_idx, value=value)\n",
    "        \n",
    "wb.save('crime_report.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"screenshots\\crime report.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced graphing with Excel and Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl.chart import BarChart, PieChart, Series, Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb=load_workbook('crime_report.xlsx')\n",
    "ws = wb.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create bar chart\n",
    "\n",
    "- top left corner to cell B14\n",
    "- data is accessed from cell A8 to M13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = BarChart()\n",
    "data = Reference(ws, min_row=10, min_col=1, max_col=13, max_row=13)\n",
    "labels = Reference(ws, min_row=8, min_col=2, max_col=13, max_row=8)\n",
    "chart.add_data(data, from_rows =True, titles_from_data = True)\n",
    "chart.set_categories(labels)\n",
    "chart.title = 'Counterfeit Crimes by District'\n",
    "chart_height=4.56 #adjust accordingly\n",
    "chart_width=20.3  #adjust accordingly\n",
    "ws.add_chart(chart, 'B14')\n",
    "wb.save('chart.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create pie chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2 = PieChart()\n",
    "data = Reference(ws, min_row=8, min_col=15, max_col=16, max_row=8)\n",
    "labels = Reference(ws, min_row=7, min_col=15, max_col=16, max_row=7)\n",
    "chart2.add_data(data, from_rows =True)\n",
    "chart2.set_categories(labels)\n",
    "chart2.title = '% Counterfeit Crimes'\n",
    "chart2_height=4.56 #adjust accordingly\n",
    "chart2_width=8.45  #adjust accordingly\n",
    "ws.add_chart(chart2, 'N14')\n",
    "wb.save('chart.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\'screenshots/chart.PNG\'>"    

   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
